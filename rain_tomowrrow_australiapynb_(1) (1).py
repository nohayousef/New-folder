# -*- coding: utf-8 -*-
"""Rain_tomowrrow_australiapynb_(1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jd-45X7zVuznliOCYAM7Udc_Sel_2-Vh

## About Dataset
## Context
Ever wondered if you should carry an umbrella tomorrow? With this dataset, you can predict next-day rain by training classification models on the target variable RainTomorrow.

## Content
This dataset comprises about 10 years of daily weather observations from numerous locations across Australia.

RainTomorrow is the target variable to predict. It answers the crucial question: will it rain the next day? (Yes or No).

This column is marked 'Yes' if the rain for that day was 1mm or more.
Source & Acknowledgements
The observations were gathered from a multitude of weather stations. You can access daily observations from http://www.bom.gov.au/climate/data.
For example, you can check the latest weather observations in Canberra here: Canberra Weather.

Definitions have been adapted from the Bureau of Meteorology's Climate Data Online.
Data source: Climate Data and Climate Data Online.

Copyright Commonwealth of Australia 2010, Bureau of Meteorology.
https://www.kaggle.com/datasets/jsphyg/weather-dataset-rattle-package/data

## 1) Understanding Data
a) Understand Columns

b) check dtype -> df[col].astype()

c) Describe Numerical Cols

d) Describe Categorical Cols

## 2) EXTRACT FEATURES + EDA (uni - bi(heatmap) - multi) -> Insights:
Uni-variate Analysis

Histogram (values)

distplot (distrbution)

catigorical (pie / count)

Bi-Variate Analysis

Num vs Num

Scatter (relationship btn 2 variables)

line (trend with time)

Num vs Cat (distrbution)

box

violin

strip

Cat vs Cat

bar (estimate plot)

countplot (count rows)

Multi-Variate Analysis

Pairplot
## 3) Pre-Processing Mind Map:
a) Detect & Handle Duplicates

b) train_test_split

c) Detect & Handle NaNs

d) Detect & Handle Outliers

e) Encoding: (Ordinal:[OrdinalEncoder, LabelEncoder] - Nominal: [< 7 uniques(OneHotEncoding), > 7 uniques (BinaryEncoder)])

f) Imbalanced: X_train_resampled

g) Scaling: StandardScaler, MinMaxScaler, RobustScaler: X_train_resampled_scaled
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade scikit-learn imbalanced-learn

# Commented out IPython magic to ensure Python compatibility.
# %pip install user_agents

# Commented out IPython magic to ensure Python compatibility.
# %pip install category_encoders

# Commented out IPython magic to ensure Python compatibility.
# %pip install imblearn

# Commented out IPython magic to ensure Python compatibility.
# The ImportError is likely due to an incompatibility between the versions of scikit-learn and other installed dependencies.
# To solve this, we should upgrade scikit-learn to ensure compatibility and fix the issue.

# Upgrading scikit-learn to the latest version
# %pip install --upgrade scikit-learn

# Once upgraded, restart the kernel and re-run the imports to check if the issue persists.

# Manpulate
import numpy as np
import pandas as pd

# Visualization
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

# Feature Extraction
# import user_agents # get info from user_agent (browser_info)
# from ip2geotools.databases.noncommercial import DbIpCity as ip2geo # get location from ip
# from geopy.distance import great_circle # distance btn 2 (lat,long)
# from geopy.geocoders import Nominatim # geocode("place") / reverse("lat,long")
# from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer # text feature

# Pre-Processing
from sklearn.model_selection import train_test_split # train-test-split
from sklearn.experimental import enable_iterative_imputer
from sklearn.impute import SimpleImputer, KNNImputer, IterativeImputer # detect & handle NaNs
from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder # Ordinal Encoding, Nominal Encoding
from category_encoders import BinaryEncoder # Nominal Encoding
from imblearn.under_sampling import RandomUnderSampler # undersampling
from imblearn.over_sampling import RandomOverSampler, SMOTE # oversampling
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler # Scaling

# Modeling

## 1) Pipeline
from sklearn.pipeline import Pipeline, make_pipeline # to make pipeline
from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector # apply pipeline to each column

## 2) Regression Models
from sklearn.linear_model import LinearRegression # if data is small and small_no_features
from sklearn.linear_model import SGDRegressor # if data is large: (can have penalty=constrains)
from sklearn.preprocessing import PolynomialFeatures # for polynomial regresion (then apply scaling after it)
from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV, ElasticNet, ElasticNetCV # Regularization

## 2') Classfication Models
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, MultinomialNB
from sklearn.svm import LinearSVC, SVC, LinearSVR, SVR
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor # Bagging & Pasting
from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier, GradientBoostingRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor # Boosting
from sklearn.ensemble import VotingClassifier, VotingRegressor # Ensemble (Voting)
from sklearn.ensemble import StackingClassifier, StackingRegressor # Stacking

## 3) Model Selection (Underfitting vs Overfitting) [bias variance tradeoff => perfect model complexity]
from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold, GridSearchCV, RandomizedSearchCV # (Train - Valid - Test) + hyperparameters tunning
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV # if data / features is large
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error # Evaluate Model: r2=> accuracy, L2-norm: if no outliers, L1-norm: if outliers
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score
from scipy import stats # Confidence Interval of Accuracy / Loss / Utility
import joblib # save model

"""## 1) Understanding Data
a) Understand Columns

b) check dtype -> df[col].astype()

c) Describe Numerical Cols

d) Describe Categorical Cols
"""

# (a) understand columns.
df = pd.read_csv("weatherAUS.csv")
df

df["Location"].unique()

# (b) check type
df.info()

df['Date'] = pd.to_datetime(df['Date'])

# (b) check type
df.info()

df['RainTomorrow'].value_counts()

def map_values(value):
    if value == 'Yes':
        return 1.0
    elif value == 'No':
        return 0.0
    elif pd.isna(value):  # Correct check for NaN
        return 0.0
    else:
        return value  # Keeps other values unchanged

# Apply mapping correctly
df['RainTomorrow'] = df['RainTomorrow'].apply(map_values)

def map_values(value):
    if value == 'Yes':
        return 1.0
    elif value == 'No':
        return 0.0
    elif pd.isna(value):  # Handles NaN values
        return 0.0
    else:
        return value  # Keeps other values unchanged

# Apply mapping to the 'RainToday' column
df['RainToday'] = df['RainToday'].apply(map_values)
df['RainToday'] = df['RainToday'].replace({'Yes': 1.0, 'No': 0.0}).fillna(0.0)

#c) Describe Numerical Cols
df.describe().T

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
sns.barplot(x=df["WindGustDir"], y=df["RainTomorrow"])
plt.xticks(rotation=90)
plt.title("Rain Probability by WindGustDir")
plt.show()

#columns_to_drop = ['Date', 'Location', 'Evaporation', 'Sunshine', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm']

#df.drop(['Date', 'Location', 'Evaporation', 'Sunshine', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm'], axis=1, inplace=True)
#df

# drop unuseful Data
#df.drop(["Ethnicity", 'Residence', 'EducationLevel', 'ECGResults', 'Income'], axis=1, inplace=True)
#df

# (d) Describe Categorical Cols

cat_cols = df.select_dtypes(include="O").columns

for col in cat_cols:
    print(f"number of uniques of \'{col}\' is: {df[col].nunique()}")
    print(f"uniques of \'{col}\' is:\n{df[col].unique()}")
    print()
    print('*' * 50)
    print()

"""*************************

## 2) EXTRACT FEATURES
"""

df.columns

df.columns = df.columns.str.strip()

# Convert 'Date' column to datetime format and extract Month
df['Date'] = pd.to_datetime(df['Date'], errors='coerce')
df['Month'] = df['Date'].dt.month

# Compute new features
df['TempDiff'] = df['MaxTemp'] - df['MinTemp']
df['HumidityDiff'] = df['Humidity9am'] - df['Humidity3pm']
df['PressureDiff'] = df['Pressure9am'] - df['Pressure3pm']
df['PrevDayRainfall'] = df.groupby('Location')['Rainfall'].shift(1)

season_map = {
    6: 'Summer', 7: 'Summer', 8: 'Summer',  # June, July, August
    9: 'Autumn', 10: 'Autumn', 11: 'Autumn',  # September, October, November
    12: 'Winter', 1: 'Winter', 2: 'Winter',  # December, January, February
    3: 'Spring', 4: 'Spring', 5: 'Spring'  # March, April, May
}
# Apply mapping
df['Season'] = df['Month'].map(season_map)
# Display sample results
df[['PrevDayRainfall', 'Season']].head()

df['PrevDayRainfall'] = df.groupby('Location')['Rainfall'].shift(1)

df['HeavyRainToday'] = (df['Rainfall'] > 5).astype(int)

df['HumidityDiff'] = df['Humidity9am'] - df['Humidity3pm']

df['HighHumidityMorning'] = (df['Humidity9am'] > 80).astype(int)

df['WindChange'] = (df['WindDir9am'] != df['WindDir3pm']).astype(int)

df['StrongWindGust'] = (df['WindGustSpeed'] > 40).astype(int)

df['CloudIncrease'] = (df['Cloud3pm'] > df['Cloud9am']).astype(int)

df['IsRainySeason'] = df['Season'].isin(['Winter', 'Spring']).astype(int)

"""****************************

## EDA (uni - bi(heatmap) - multi) -> Insights:
Uni-variate Analysis

Histogram (values)

distplot (distrbution)

catigorical (pie / count)

Bi-Variate Analysis

Num vs Num

Scatter (relationship btn 2 variables)

line (trend with time)

Num vs Cat (distrbution)

box

violin

strip

Cat vs Cat

bar (estimate plot)

countplot (count rows)

Multi-Variate Analysis
"""

# UniVariate Analysis

num_cols = df.select_dtypes(include="number").columns

for col in num_cols:
    fig, axes= plt.subplots(nrows=1, ncols=2)
    sns.histplot(df[col], kde=True, ax=axes[0])
    sns.boxplot(x=df[col], ax=axes[1])
    plt.show()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Identify categorical (object) columns
categorical_columns = df.select_dtypes(include='object').columns

for col in categorical_columns:
    plt.figure(figsize=(12, 6))  # Set figure size
    value_counts = df[col].value_counts()

    # If too many categories, group smaller ones as "Other"
    if len(value_counts) > 10:
        top_10 = value_counts[:10]
        other_sum = value_counts[10:].sum()
        value_counts = pd.concat([top_10, pd.Series({'Other': other_sum})], axis=0)

    # Convert to DataFrame for sns.barplot()
    value_counts_df = value_counts.reset_index()
    value_counts_df.columns = [col, "Count"]

    # Define colors
    colors = sns.color_palette("pastel", len(value_counts_df))

    # Create bar plot
    ax = sns.barplot(x=col, y="Count", data=value_counts_df, palette=colors)

    # Reduce the y-axis range to make bars more visible
    max_count = value_counts_df["Count"].max()
    min_count = value_counts_df["Count"].min()
    ax.set_ylim(min_count * 0.8, max_count * 1.2)  # Adjust limits to show all bars properly

    # Apply log scale if needed (optional)
    if max_count > 10000:
        ax.set_yscale("log")  # Only apply log scale if max value is very large

    # Improve styling
    plt.xticks(rotation=45, ha='right', fontsize=12)  # Rotate labels
    plt.yticks(fontsize=12)
    plt.xlabel(col, fontsize=14, fontweight='bold')
    plt.ylabel("Count", fontsize=14, fontweight='bold')
    plt.title(f"Distribution of {col}", fontsize=16, fontweight='bold')
    plt.grid(axis="y", linestyle="--", alpha=0.7)  # Add grid for readability

    plt.show()

# Bi-Variate
# Set larger figure size
plt.figure(figsize=(20, 10))  # Adjust width and height as needed
# Generate heatmap
sns.heatmap(df.select_dtypes(include='number').corr(), annot=True, fmt='.2f', cmap='coolwarm')
# Show plot
plt.show()

df.columns

#columns_to_drop = ['Date', 'Location', 'Evaporation', 'Sunshine', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm']

df.drop(['Date', 'PressureDiff', 'Month', 'TempDiff','HumidityDiff','Temp9am','Temp3pm','Pressure3pm','Pressure9am','WindSpeed3pm','WindSpeed9am', 'CloudIncrease', 'IsRainySeason','HighHumidityMorning'], axis=1, inplace=True)
df



# Bi-Variate
# Set larger figure size
plt.figure(figsize=(12, 8))  # Adjust width and height as needed
# Generate heatmap
sns.heatmap(df.select_dtypes(include='number').corr(), annot=True, fmt='.2f', cmap='coolwarm')
# Show plot
plt.show()

df.columns

#columns_to_drop = ['Date', 'Location', 'Evaporation', 'Sunshine', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm']

df.drop(['MinTemp', 'MaxTemp'], axis=1, inplace=True)
df

#Evaporation
df.drop(['Evaporation'], axis=1, inplace=True)
df

df.columns

# (d) Describe Categorical Cols

cat_cols = df.select_dtypes(include="O").columns

for col in cat_cols:
    print(f"number of uniques of \'{col}\' is: {df[col].nunique()}")
    print(f"uniques of \'{col}\' is:\n{df[col].unique()}")
    print()
    print('*' * 50)
    print()

df['Season'].isna().sum()

# MultiVariate

sns.pairplot(df.select_dtypes(include='number'))

"""*********************************************

## 3) Pre-Processing Mind Map:¶
a) Detect & Handle Duplicates

b) train_test_split

c) Detect & Handle NaNs

d) Detect & Handle Outliers

e) Encoding: (Ordinal:[OrdinalEncoder, LabelEncoder] - Nominal: [< 7 uniques(OneHotEncoding), > 7 uniques (BinaryEncoder)])

f) Imbalanced: X_train_resampled

g) Scaling: StandardScaler, MinMaxScaler, RobustScaler: X_train_resampled_scaled
"""

df.columns

df

# a) Detect & Handle Duplicates

df.duplicated().sum()

df.drop_duplicates(inplace=True)
df

df.duplicated().sum()

# b) train_test_split

X = df.drop(["RainTomorrow"], axis=1)
y = df['RainTomorrow']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, stratify=y, random_state=42)
X_train

# X_train.drop_duplicates(inplace=True)
# X_train

X_train.shape

X_test.shape # good enough

y_train.shape

X_train.isna().sum()

#X_train.dropna(inplace=True)

from sklearn.base import TransformerMixin, BaseEstimator


class LogTransformer(BaseEstimator, TransformerMixin):

    # fit
    def fit(self, X, y=None):
        # self.feature_names = list(X.columns)
        self.n_features_in = X.shape[1]
        return self

    # transformer
    def transform(self, X, y=None):
        assert self.n_features_in == X.shape[1]
        return np.log(X)

    # def get_feature_names_out(self, X, y=None):
    #     return self.feature_names



log_transformer = LogTransformer()
log_transformer

X_train.columns



# Check if any of the selected columns have 0 or negative values
cols_to_check = ["Humidity9am","Rainfall", 'WindGustSpeed','PrevDayRainfall']
zero_or_negative_counts = (X_train[cols_to_check] <= 0).sum()

print("Count of zero or negative values per column:")
print(zero_or_negative_counts)

"""from sklearn.preprocessing import OrdinalEncoder

# Correct the Pipeline for ordinal encoding
season_ordinal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),  # Fill missing values with most frequent
    ('ordinal_encode', OrdinalEncoder(categories=[['Summer', 'Autumn', 'Winter', 'Spring']]))  # Apply ordinal encoding
])

# Recreate the ColumnTransformer with the corrected pipeline
preprocessor = ColumnTransformer(transformers=[
    ('cat_binary_pipe', cat_binary_pipe, ['Location', 'WindGustDir','WindDir9am', 'WindDir3pm']),
    ('boolean_categorical_pipe', boolean_categorical_pipe, ['RainToday', 'HeavyRainToday','StrongWindGust']),
    ('log_transform_pipe', log_transform_pipe, ["Rainfall", 'WindGustSpeed','PrevDayRainfall']),
    ('humidity_pipe', humidity_pipe, ["Humidity9am"]),
    ('normal_pipe', normal_pipe, ['Sunshine','Humidity3pm','Cloud9am', 'Cloud3pm']),
    ("season_ordinal_pipe", season_ordinal_pipe, ['Season']) # Correct column name to 'Season'
], remainder='passthrough') # Passthrough any remaining columns

preprocessor
"""

# # **Label Encoding for Target Variables (if necessary)**
# # Assuming 'RainToday' needs Label Encoding
# # This step might be removed depending on if RainToday is in X_train or y_train
# # If RainToday is in y_train, then it should be label encoded separately.
# #label_encoders = {}
# #if 'RainToday' in X_train.columns:  # Only label encode if 'RainToday' is in X_train
#     le = LabelEncoder()
#     X_train['RainToday'] = le.fit_transform(X_train['RainToday'])  # Fit on X_train
#     X_test['RainToday'] = le.transform(X_test['RainToday'])  # Transform X_test
#     label_encoders['RainToday'] = le  # Store encoder for future use

X_train.columns

df.info()

X_train['Season']

# The issue is that log transformation could result in inf values if input values are below 1.
# To fix this, I will ensure all values used in log_transform_pipe are capped to a minimum positive threshold before applying logarithm.

# Additional Safeguard to remove infinity values prior to processing
import numpy as np
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, RobustScaler, FunctionTransformer, OneHotEncoder
from sklearn.impute import SimpleImputer
from category_encoders.binary import BinaryEncoder

# Safe log transformation function
log_transformer = FunctionTransformer(
    lambda x: np.log1p(np.clip(np.nan_to_num(x, nan=0), a_min=1e-6, a_max=None)),
    validate=False  # Ensures it works with DataFrames too
)
# **Pipeline for Binary Encoding**
cat_binary_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', BinaryEncoder(drop_invariant=False)),

])

# **Pipeline for One-Hot Encoding of Boolean Features**
boolean_categorical_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),

])

# **Pipeline for Log Transformation**
rightskew_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    ('scale', RobustScaler())
])

# **Pipeline for Humidity-related Features**
humidity_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    ('scale', RobustScaler(with_centering=False))
])

# **Numerical Imputation and Scaling**
normal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('scale', RobustScaler())
])

season_ordinal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),  # Fill missing values with most frequent
    ('ordinal_encode', OrdinalEncoder(categories=[['Summer', 'Autumn', 'Winter', 'Spring']]))  # Apply ordinal encoding
])

# ColumnTransformer combining all pipelines
preprocessor = ColumnTransformer(transformers=[
    ('cat_binary_pipe', cat_binary_pipe, ['Location', 'WindGustDir','WindDir9am', 'WindDir3pm']),
    ('boolean_categorical_pipe', boolean_categorical_pipe, ['RainToday', 'HeavyRainToday','StrongWindGust']),
    ('rightskew_pipe', rightskew_pipe, ["Rainfall", 'WindGustSpeed','PrevDayRainfall']),
    ('humidity_pipe', humidity_pipe, ["Humidity9am"]),
    ('normal_pipe', normal_pipe, ['Sunshine','Humidity3pm','Cloud9am', 'Cloud3pm']),
    ("season_ordinal_pipe", season_ordinal_pipe, ['Season']) # Correct column name to 'Season'
], remainder='passthrough') # Passthrough any remaining columns
preprocessor

# # **Ensure X_train is Defined Before Using It**
# try:
#     X_train_scaled = preprocessor.fit_transform(X_train)
#     print("Preprocessing Successful! Transformed Data Shape:", X_train_scaled.shape)
# except NameError as e:
#     print("Error: Ensure X_train is defined and contains the specified columns.")
#     print(str(e))
# except Exception as e:
#     print("Unexpected Error:", str(e))

X_trian_scaled = preprocessor.fit_transform(X_train)
X_trian_scaled

X_trian_scaled.shape

X_test_scaled = preprocessor.transform(X_test)
X_test_scaled

X_test_scaled.shape

"""# Model"""

# Modeling

## 1) Pipeline
from sklearn.pipeline import Pipeline, make_pipeline # to make pipeline
from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector # apply pipeline to each column

## 2) Regression Models
from sklearn.linear_model import LinearRegression # if data is small and small_no_features
from sklearn.linear_model import SGDRegressor # if data is large: (can have penalty=constrains)
from sklearn.preprocessing import PolynomialFeatures # for polynomial regresion (then apply scaling after it)
from sklearn.linear_model import Lasso, LassoCV, Ridge, RidgeCV, ElasticNet, ElasticNetCV # Regularization

## 2') Classfication Models
from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor
from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB, MultinomialNB
from sklearn.svm import LinearSVC, SVC, LinearSVR, SVR
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestClassifier, RandomForestRegressor, ExtraTreesClassifier, ExtraTreesRegressor # Bagging & Pasting
from sklearn.ensemble import AdaBoostClassifier, AdaBoostRegressor, GradientBoostingClassifier, GradientBoostingRegressor, HistGradientBoostingClassifier, HistGradientBoostingRegressor # Boosting
from sklearn.ensemble import VotingClassifier, VotingRegressor # Ensemble (Voting)
from sklearn.ensemble import StackingClassifier, StackingRegressor # Stacking

## 3) Model Selection (Underfitting vs Overfitting) [bias variance tradeoff => perfect model complexity]
from sklearn.model_selection import cross_val_score, cross_val_predict, StratifiedKFold, GridSearchCV, RandomizedSearchCV # (Train - Valid - Test) + hyperparameters tunning
from sklearn.experimental import enable_halving_search_cv
from sklearn.model_selection import HalvingGridSearchCV, HalvingRandomSearchCV # if data / features is large
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error # Evaluate Model: r2=> accuracy, L2-norm: if no outliers, L1-norm: if outliers
from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score
from scipy import stats # Confidence Interval of Accuracy / Loss / Utility
import joblib # save model

log_reg = LogisticRegression(random_state=42, C=1.0, max_iter=100, warm_start=True, class_weight='balanced')
log_reg.fit(X_trian_scaled, y_train)

log_reg.score(X_trian_scaled, y_train)

y_valid_pred = cross_val_predict(log_reg, X_trian_scaled, y_train, cv=3)
confusion_matrix(y_true=y_train, y_pred=y_valid_pred)

# Perform cross-validation predictions
y_valid_pred = cross_val_predict(log_reg, X_trian_scaled, y_train, cv=3)

# Compute confusion matrix
cm = confusion_matrix(y_true=y_train, y_pred=y_valid_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap="Blues", linewidths=0.5, cbar=False)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

y_train_pred = log_reg.predict(X_trian_scaled)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")
print(f"Validation Accuracy: {accuracy_score(y_train, y_valid_pred)}")
print(f"Validation Precision Score: {precision_score(y_train, y_valid_pred)}")
print(f"Validation Recall Score: {recall_score(y_train, y_valid_pred)}")
print(f"Validation f1 Score: {f1_score(y_train, y_valid_pred)}")

"""# ## Underfitting Solutions:

1) More Complex Model

2) Extract More Features (PolynomialFeatures)

3) descrease constrains
"""

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, RobustScaler, FunctionTransformer, OneHotEncoder, PolynomialFeatures, StandardScaler
from sklearn.impute import SimpleImputer
from category_encoders.binary import BinaryEncoder

# Safe log transformation function
log_transformer = FunctionTransformer(
    lambda x: np.log1p(np.clip(np.nan_to_num(x, nan=0), a_min=1e-6, a_max=None)),
    validate=False
)



# **Pipeline for Binary Encoding**
cat_binary_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', BinaryEncoder(drop_invariant=False)),
])

# **Pipeline for One-Hot Encoding**
boolean_categorical_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),
])

# **Pipeline for Log Transformation**
rightskew_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Pipeline for Humidity Features**
humidity_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler(with_centering=False))
])

# **Pipeline for Numerical Imputation & Scaling**
normal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Ordinal Encoding for Seasons**
season_ordinal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('ordinal_encode', OrdinalEncoder(categories=[['Summer', 'Autumn', 'Winter', 'Spring']])),
])

# **Pipeline for Polynomial Features (Degree 2)**
poly_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='mean')),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),  # Keeping degree moderate to prevent high dimensionality
    ('scale', StandardScaler()),
])

# **Final Column Transformer**
preprocessor = ColumnTransformer(transformers=[
    #('date_features', date_feature_pipe, ['Date']),
    ('cat_binary_pipe', cat_binary_pipe, ['Location', 'WindGustDir','WindDir9am', 'WindDir3pm']),
    ('boolean_categorical_pipe', boolean_categorical_pipe, ['RainToday', 'HeavyRainToday', 'StrongWindGust']),
    ('rightskew_pipe', rightskew_pipe, ["Rainfall", 'WindGustSpeed', 'PrevDayRainfall']),
    ('humidity_pipe', humidity_pipe, ["Humidity9am"]),
    ('normal_pipe', normal_pipe, ['Sunshine', 'Humidity3pm', 'Cloud9am', 'Cloud3pm']),
    ('season_ordinal_pipe', season_ordinal_pipe, ['Season']),
    ('poly_pipe', poly_pipe, ["Rainfall", "WindGustSpeed", "Humidity9am", "Humidity3pm"]),  # Added polynomial features
], remainder='passthrough')

# Transform data
X_train_scaled = preprocessor.fit_transform(X_train)
X_test_scaled = preprocessor.transform(X_test)

from sklearn.linear_model import LogisticRegression

# Optimized Logistic Regression Model
log_reg = LogisticRegression(C=0.1,  penalty='l2',  solver='liblinear', random_state=42,  max_iter=500,  tol=1e-7
)
log_reg

log_reg = LogisticRegression(random_state=42, C=1.0, max_iter=2000, warm_start=False, class_weight='balanced')
log_reg.fit(X_train_scaled, y_train)
y_train_pred = log_reg.predict(X_train_scaled) # train
y_valid_pred = cross_val_predict(log_reg, X_train_scaled, y_train, cv=3) # valid
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")
print(f"Validation Accuracy: {accuracy_score(y_train, y_valid_pred)}")

## More Complex Model

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, RobustScaler, FunctionTransformer, OneHotEncoder, PolynomialFeatures, StandardScaler
from sklearn.impute import SimpleImputer
from category_encoders.binary import BinaryEncoder

# Safe log transformation function
log_transformer = FunctionTransformer(
    lambda x: np.log1p(np.clip(np.nan_to_num(x, nan=0), a_min=1e-6, a_max=None)),
    validate=False
)



# **Pipeline for Binary Encoding**
cat_binary_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', BinaryEncoder(drop_invariant=False)),
])

# **Pipeline for One-Hot Encoding**
boolean_categorical_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),
])

# **Pipeline for Log Transformation**
rightskew_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Pipeline for Humidity Features**
humidity_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler(with_centering=False))
])

# **Pipeline for Numerical Imputation & Scaling**
normal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Ordinal Encoding for Seasons**
season_ordinal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('ordinal_encode', OrdinalEncoder(categories=[['Summer', 'Autumn', 'Winter', 'Spring']])),
])

# **Pipeline for Polynomial Features (Degree 2)**
poly_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='mean')),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),  # Keeping degree moderate to prevent high dimensionality
    ('scale', StandardScaler()),
])

# **Final Column Transformer**
preprocessor = ColumnTransformer(transformers=[
    #('date_features', date_feature_pipe, ['Date']),
    ('cat_binary_pipe', cat_binary_pipe, ['Location', 'WindGustDir','WindDir9am', 'WindDir3pm']),
    ('boolean_categorical_pipe', boolean_categorical_pipe, ['RainToday', 'HeavyRainToday', 'StrongWindGust']),
    ('rightskew_pipe', rightskew_pipe, ["Rainfall", 'WindGustSpeed', 'PrevDayRainfall']),
    ('humidity_pipe', humidity_pipe, ["Humidity9am"]),
    ('normal_pipe', normal_pipe, ['Sunshine', 'Humidity3pm', 'Cloud9am', 'Cloud3pm']),
    ('season_ordinal_pipe', season_ordinal_pipe, ['Season']),
    #('poly_pipe', poly_pipe, ["Rainfall", "WindGustSpeed", "Humidity9am", "Humidity3pm"]),  # Added polynomial features
], remainder='passthrough')

# Transform data
X_train_scaled = preprocessor.fit_transform(X_train)
X_test_scaled = preprocessor.transform(X_test)

# Initialize the LinearSVC model
linear_svc_clf = LinearSVC(C=1, random_state=42, max_iter=10000, class_weight='balanced', loss='hinge')

linear_svc_clf.fit(X_train_scaled, y_train)

y_train_pred = linear_svc_clf.predict(X_train_scaled)  # train# Predict on training data

y_valid_pred = cross_val_predict(linear_svc_clf, X_train_scaled, y_train, cv=3)  # valid

# Print accuracy scores
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")
print(f"Validation Accuracy: {accuracy_score(y_train, y_valid_pred)}")

svc_clf = SVC(C=1, kernel='poly', degree=3, coef0=10, random_state=42, class_weight='balanced')
svc_clf.fit(X_train_scaled, y_train)
y_train_pred = svc_clf.predict(X_train_scaled) # train
y_valid_pred = cross_val_predict(svc_clf, X_train_scaled, y_train, cv=3) # valid
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")
print(f"Validation Accuracy: {accuracy_score(y_train, y_valid_pred)}")

"""## Let’s solve imbalanced[(1) undersampling **bold text**(2) oversampling]

# (a) Undersampling
"""

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, RobustScaler, FunctionTransformer, OneHotEncoder, PolynomialFeatures, StandardScaler
from sklearn.impute import SimpleImputer
from category_encoders.binary import BinaryEncoder

# Safe log transformation function
log_transformer = FunctionTransformer(
    lambda x: np.log1p(np.clip(np.nan_to_num(x, nan=0), a_min=1e-6, a_max=None)),
    validate=False
)



# **Pipeline for Binary Encoding**
cat_binary_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', BinaryEncoder(drop_invariant=False)),
])

# **Pipeline for One-Hot Encoding**
boolean_categorical_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),
])

# **Pipeline for Log Transformation**
rightskew_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Pipeline for Humidity Features**
humidity_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler(with_centering=False))
])

# **Pipeline for Numerical Imputation & Scaling**
normal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Ordinal Encoding for Seasons**
season_ordinal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('ordinal_encode', OrdinalEncoder(categories=[['Summer', 'Autumn', 'Winter', 'Spring']])),
])

# **Pipeline for Polynomial Features (Degree 2)**
poly_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='mean')),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),  # Keeping degree moderate to prevent high dimensionality
    ('scale', StandardScaler()),
])

# **Final Column Transformer**
poly_preprocessor  = ColumnTransformer(transformers=[
    #('date_features', date_feature_pipe, ['Date']),
    ('cat_binary_pipe', cat_binary_pipe, ['Location', 'WindGustDir','WindDir9am', 'WindDir3pm']),
    ('boolean_categorical_pipe', boolean_categorical_pipe, ['RainToday', 'HeavyRainToday', 'StrongWindGust']),
    ('rightskew_pipe', rightskew_pipe, ["Rainfall", 'WindGustSpeed', 'PrevDayRainfall']),
    ('humidity_pipe', humidity_pipe, ["Humidity9am"]),
    ('normal_pipe', normal_pipe, ['Sunshine', 'Humidity3pm', 'Cloud9am', 'Cloud3pm']),
    ('season_ordinal_pipe', season_ordinal_pipe, ['Season']),
    ('poly_pipe', poly_pipe, ["Rainfall", "WindGustSpeed", "Humidity9am", "Humidity3pm"]),  # Added polynomial features
], remainder='passthrough')

# Transform data
#X_train_scaled = preprocessor.fit_transform(X_train)
#X_test_scaled = preprocessor.transform(X_test)

from imblearn.pipeline import Pipeline as Imb_Pipeline

undersampling_polyfeats_pipeline = Imb_Pipeline(steps=[
    ('poly_preprocessor', poly_preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
])

undersampling_polyfeats_pipeline

# import numpy as np
# import pandas as pd
# from sklearn.compose import ColumnTransformer
# from sklearn.pipeline import Pipeline
# from sklearn.preprocessing import OrdinalEncoder, RobustScaler, FunctionTransformer, OneHotEncoder, PolynomialFeatures, StandardScaler
# from sklearn.impute import SimpleImputer
# from category_encoders.binary import BinaryEncoder

# # Safe log transformation function
# log_transformer = FunctionTransformer(
#     lambda x: np.log1p(np.clip(np.nan_to_num(x, nan=0), a_min=1e-6, a_max=None)),
#     validate=False
# )



# # **Pipeline for Binary Encoding**
# cat_binary_pipe = Pipeline(steps=[
#     ('handle_nans', SimpleImputer(strategy='most_frequent')),
#     ('encode', BinaryEncoder(drop_invariant=False)),
# ])

# # **Pipeline for One-Hot Encoding**
# boolean_categorical_pipe = Pipeline(steps=[
#     ('handle_nans', SimpleImputer(strategy='most_frequent')),
#     ('encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),
# ])

# # **Pipeline for Log Transformation**
# rightskew_pipe = Pipeline(steps=[
#     ('handle_nans', SimpleImputer(strategy='median')),
#     ('handle_outliers', log_transformer),
#     #('poly', PolynomialFeatures(degree=5, include_bias=False)),
#     ('scale', RobustScaler())
# ])

# # **Pipeline for Humidity Features**
# humidity_pipe = Pipeline(steps=[
#     ('handle_nans', SimpleImputer(strategy='median')),
#     ('handle_outliers', log_transformer),
#     #('poly', PolynomialFeatures(degree=5, include_bias=False)),
#     ('scale', RobustScaler(with_centering=False))
# ])

# # **Pipeline for Numerical Imputation & Scaling**
# normal_pipe = Pipeline(steps=[
#     ('handle_nans', SimpleImputer(strategy='median')),
#     #('poly', PolynomialFeatures(degree=5, include_bias=False)),
#     ('scale', RobustScaler())
# ])

# # **Ordinal Encoding for Seasons**
# season_ordinal_pipe = Pipeline(steps=[
#     ('handle_nans', SimpleImputer(strategy='most_frequent')),
#     ('ordinal_encode', OrdinalEncoder(categories=[['Summer', 'Autumn', 'Winter', 'Spring']])),
# ])

# # **Pipeline for Polynomial Features (Degree 2)**
# poly_pipe = Pipeline(steps=[
#     ('handle_nans', SimpleImputer(strategy='mean')),
#     #('poly', PolynomialFeatures(degree=5, include_bias=False)),  # Keeping degree moderate to prevent high dimensionality
#     ('scale', StandardScaler()),
# ])

# # **Final Column Transformer**
# preprocessor = ColumnTransformer(transformers=[
#     #('date_features', date_feature_pipe, ['Date']),
#     ('cat_binary_pipe', cat_binary_pipe, ['Location', 'WindGustDir','WindDir9am', 'WindDir3pm']),
#     ('boolean_categorical_pipe', boolean_categorical_pipe, ['RainToday', 'HeavyRainToday', 'StrongWindGust']),
#     ('rightskew_pipe', rightskew_pipe, ["Rainfall", 'WindGustSpeed', 'PrevDayRainfall']),
#     ('humidity_pipe', humidity_pipe, ["Humidity9am"]),
#     ('normal_pipe', normal_pipe, ['Sunshine', 'Humidity3pm', 'Cloud9am', 'Cloud3pm']),
#     ('season_ordinal_pipe', season_ordinal_pipe, ['Season']),
#     #('poly_pipe', poly_pipe, ["Rainfall", "WindGustSpeed", "Humidity9am", "Humidity3pm"]),  # Added polynomial features
# ], remainder='passthrough')

# # Transform data
# #X_train_scaled = preprocessor.fit_transform(X_train)
# #X_test_scaled = preprocessor.transform(X_test)

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, RobustScaler, FunctionTransformer, OneHotEncoder, PolynomialFeatures, StandardScaler
from sklearn.impute import SimpleImputer
from category_encoders.binary import BinaryEncoder

# Safe log transformation function
log_transformer = FunctionTransformer(
    lambda x: np.log1p(np.clip(np.nan_to_num(x, nan=0), a_min=1e-6, a_max=None)),
    validate=False
)



# **Pipeline for Binary Encoding**
cat_binary_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', BinaryEncoder(drop_invariant=False)),
])

# **Pipeline for One-Hot Encoding**
boolean_categorical_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),
])

# **Pipeline for Log Transformation**
rightskew_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Pipeline for Humidity Features**
humidity_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler(with_centering=False))
])

# **Pipeline for Numerical Imputation & Scaling**
normal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Ordinal Encoding for Seasons**
season_ordinal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('ordinal_encode', OrdinalEncoder(categories=[['Summer', 'Autumn', 'Winter', 'Spring']])),
])

# **Pipeline for Polynomial Features (Degree 2)**
poly_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='mean')),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),  # Keeping degree moderate to prevent high dimensionality
    ('scale', StandardScaler()),
])

# **Final Column Transformer**
preprocessor = ColumnTransformer(transformers=[
    #('date_features', date_feature_pipe, ['Date']),
    ('cat_binary_pipe', cat_binary_pipe, ['Location', 'WindGustDir','WindDir9am', 'WindDir3pm']),
    ('boolean_categorical_pipe', boolean_categorical_pipe, ['RainToday', 'HeavyRainToday', 'StrongWindGust']),
    ('rightskew_pipe', rightskew_pipe, ["Rainfall", 'WindGustSpeed', 'PrevDayRainfall']),
    ('humidity_pipe', humidity_pipe, ["Humidity9am"]),
    ('normal_pipe', normal_pipe, ['Sunshine', 'Humidity3pm', 'Cloud9am', 'Cloud3pm']),
    ('season_ordinal_pipe', season_ordinal_pipe, ['Season']),
    #('poly_pipe', poly_pipe, ["Rainfall", "WindGustSpeed", "Humidity9am", "Humidity3pm"]),  # Added polynomial features
], remainder='passthrough')


from imblearn.pipeline import Pipeline as Imb_Pipeline

undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
])

undersampling_pipeline

"""## (2) Underfitting vs Overfitting
We now know dataset in not linear
(so let's try [KNN - GaussianNB - SVC - DT - Ensamble])
"""

# Logestic Regression
from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

undersampling_pipeline = Imb_Pipeline(steps=[
    ('poly_preprocessor', poly_preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", LogisticRegression(C=1.0, max_iter=1000, random_state=42))
    ])
undersampling_pipeline.fit(X_train, y_train)
y_train_pred = undersampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", LogisticRegression(C=1.0, max_iter=500, random_state=42))
    ])

    undersampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = undersampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# KNN

from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", KNeighborsClassifier(n_neighbors=77, leaf_size=50))
    ])
undersampling_pipeline.fit(X_train, y_train)
y_train_pred = undersampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", KNeighborsClassifier(n_neighbors=77, leaf_size=50))
    ])

    undersampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = undersampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precision: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# # GaussianNB



# from sklearn.model_selection import KFold

# valid_accuracy_score = []
# valid_f1_score = []
# valid_precision_score = []
# valid_recall_score = []

# undersampling_pipeline = Imb_Pipeline(steps=[
#     ('preprocessor', preprocessor),
#     ('solve_imbalanced', RandomUnderSampler(random_state=42)),
#     ("model", GaussianNB())
#     ])
# undersampling_pipeline.fit(X_train, y_train)
# y_train_pred = undersampling_pipeline.predict(X_train)
# print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

# skfolds = StratifiedKFold(n_splits=5)
# i = 1
# for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
#     print(f"At fold {i}")
#     # print(y_train.iloc[train_indx].value_counts(normalize=True))
#     # print(y_train.iloc[valid_indx].value_counts(normalize=True))
#     # print()

#     undersampling_pipeline = Imb_Pipeline(steps=[
#     ('preprocessor', preprocessor),
#     ('solve_imbalanced', RandomUnderSampler(random_state=42)),
#     ("model", GaussianNB())
#     ])

#     undersampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
#     y_valid_pred = undersampling_pipeline.predict(X_train.iloc[valid_indx])

#     valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

#     i += 1

# print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
# print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
# print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
# print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# SVC



from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", SVC(C=1.0, kernel='poly', degree=4, coef0=10, random_state=42))
    ])
undersampling_pipeline.fit(X_train, y_train)
y_train_pred = undersampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", SVC(C=1.0, kernel='poly', degree=4, coef0=10, random_state=42))
    ])

    undersampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = undersampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# DT

from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", DecisionTreeClassifier(max_depth=5, random_state=42, min_samples_split=20, min_samples_leaf=10))
    ])
undersampling_pipeline.fit(X_train, y_train)
y_train_pred = undersampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", DecisionTreeClassifier(max_depth=5, random_state=42, min_samples_split=20, min_samples_leaf=10))
    ])

    undersampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = undersampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

"""## (3) GridSearchCV

### undersambleing
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install imblearn

# Commented out IPython magic to ensure Python compatibility.
# %pip install imblearn

print(undersampling_pipeline.get_params().keys())

# Logestic Regression
from sklearn.model_selection import KFold
params_grid = {
    'model__penalty': ['l2'],
    'model__C': [0.1, 50],  # Continuous range instead of fixed values
    'poly_preprocessor__normal_pipe__poly__degree': [3, 5],  # Reduced values
    'poly_preprocessor__rightskew_pipe__poly__degree': [3, 5],
    'poly_preprocessor__poly_pipe__poly__degree': [3, 5],
}

# params_grid = {
  #  'model__penalty': ['l2'],
   # 'model__C': [0.1, 1, 3, 5, 50],
   # 'poly_preprocessor__normal_pipe__poly__degree': [3, 5, 10],
    #'poly_preprocessor__rightskew_pipe__poly__degree': [3, 5, 10],  # Corrected
    #'poly_preprocessor__poly_pipe__poly__degree': [3, 5, 10],
#}


undersampling_pipeline = Imb_Pipeline(steps=[
    ('poly_preprocessor', poly_preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", LogisticRegression(C=1.0, max_iter=1000, random_state=42)) # 135 Model
    ])

logestic_grid = GridSearchCV(undersampling_pipeline, params_grid, cv=3, n_jobs=-1, scoring='f1') # 405 Model

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 2025 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    logestic_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx]) # 405 Model
    best_logestic_model = logestic_grid.best_estimator_
    y_valid_pred = logestic_grid.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1



print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# Commented out IPython magic to ensure Python compatibility.
# %pip install imblearn

from sklearn.model_selection import StratifiedKFold, GridSearchCV
from sklearn.linear_model import LogisticRegression
from imblearn.pipeline import Pipeline as Imb_Pipeline
from imblearn.under_sampling import RandomUnderSampler
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import numpy as np

# Define parameters for GridSearchCV
params_grid = {
    'model__penalty': ['l2'],
    'model__C': [0.1, 1, 3, 5, 50],
    'poly_preprocessor__normal_pipe__poly__degree': [3, 5, 10],
    'poly_preprocessor__rightskew_pipe__poly__degree': [3, 5, 10],
    'poly_preprocessor__poly_pipe__poly__degree': [3, 5, 10],
}

# Create undersampling pipeline
undersampling_pipeline = Imb_Pipeline(steps=[
    ('poly_preprocessor', poly_preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ('model', LogisticRegression(max_iter=1000, random_state=42))
])

# Use Stratified K-Folds
skfolds = StratifiedKFold(n_splits=5)

# Run GridSearchCV once with cross-validation
logestic_grid = GridSearchCV(
    undersampling_pipeline, params_grid, cv=skfolds, n_jobs=-1, scoring='f1'
)

# Fit the model only once across all folds
logestic_grid.fit(X_train, y_train)

# Get best model and predictions
best_logestic_model = logestic_grid.best_estimator_
y_valid_pred = logestic_grid.predict(X_train)

# Compute metrics
valid_accuracy_score = accuracy_score(y_train, y_valid_pred)
valid_f1_score = f1_score(y_train, y_valid_pred)
valid_precision_score = precision_score(y_train, y_valid_pred)
valid_recall_score = recall_score(y_train, y_valid_pred)

# Print results
print(f"Valid Accuracy: {valid_accuracy_score:.4f}")
print(f"Valid F1 Score: {valid_f1_score:.4f}")
print(f"Valid Precision: {valid_precision_score:.4f}")
print(f"Valid Recall: {valid_recall_score:.4f}")

best_logestic_model

logestic_grid.best_params_

logestic_grid

best_logestic_model.fit(X_train, y_train)

# KNN

from sklearn.model_selection import KFold
params_grid = {'model__n_neighbors': [21, 31, 51, 71, 101],
               'model__leaf_size':[30, 40, 50, 60, 80, 100],
               }



undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", KNeighborsClassifier(n_neighbors=77, leaf_size=50)) # 135 Model
    ])

knn_grid = GridSearchCV(undersampling_pipeline, params_grid, cv=3, n_jobs=-1, scoring='f1') # 405 Model

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train):
    print(f"At fold {i}")

    knn_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    best_knn_model = knn_grid.best_estimator_
    y_valid_pred = knn_grid.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1



print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

best_knn_model

knn_grid.best_params_

knn_grid

best_knn_model.fit(X_train, y_train)

# SVC

from sklearn.model_selection import KFold
params_grid = [{'model__C': [1,50],
               'model__kernel':['poly'],
               'model__degree':[2, 3, 4, 5, 7],
               'model__coef0':[5, 10],
               },
               {'model__C': [1,50],
               'model__kernel':['rbf'],
               'model__gamma':['scale', 0.1, 0.5, 0.8, 1],
               }
              ]

# params_grid = {'model__C': [1.0, 20, 50],
#                'model__kernel':['poly'],
#                'model__degree':[2, 3, 4],
#                'model__coef0':[5, 10],
#                }

undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", SVC(C=1.0, kernel='poly', degree=4, coef0=10, random_state=42)) # 33 Model
    ])

svm_clf_grid = HalvingGridSearchCV(undersampling_pipeline, params_grid, cv=3, n_jobs=-1, random_state=42, scoring='f1') # 30 Model

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 150 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    svm_clf_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx]) # 30 Model
    best_svm_clf_model = svm_clf_grid.best_estimator_
    y_valid_pred = svm_clf_grid.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1
print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}")  B# Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

best_svm_clf_model

svm_clf_grid.best_params_

best_svm_clf_model.fit(X_train, y_train)

# DT

from sklearn.model_selection import KFold
params_grid = {'model__max_depth': [3, 5, 7, 10, 20],
               'model__max_leaf_nodes':[5, 10, 20],
               'model__min_samples_split':[20, 25, 30],
               'model__min_samples_leaf':[10, 20, 30],
               }



undersampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", DecisionTreeClassifier(max_depth=5, max_leaf_nodes=5, random_state=42, min_samples_split=20, min_samples_leaf=10)) # 135 Model
    ])

dt_clf_grid = GridSearchCV(undersampling_pipeline, params_grid, cv=3, n_jobs=-1, scoring='f1') # 405 Model

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 2025 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    dt_clf_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx]) # 405 Model
    best_dt_clf_model = dt_clf_grid.best_estimator_
    y_valid_pred = dt_clf_grid.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1
print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

best_dt_clf_model

dt_clf_grid.best_params_

best_dt_clf_model.fit(X_train, y_train)

"""## (b) **Oversampling**"""

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, RobustScaler, FunctionTransformer, OneHotEncoder, PolynomialFeatures, StandardScaler
from sklearn.impute import SimpleImputer
from category_encoders.binary import BinaryEncoder

# Safe log transformation function
log_transformer = FunctionTransformer(
    lambda x: np.log1p(np.clip(np.nan_to_num(x, nan=0), a_min=1e-6, a_max=None)),
    validate=False
)



# **Pipeline for Binary Encoding**
cat_binary_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', BinaryEncoder(drop_invariant=False)),
])

# **Pipeline for One-Hot Encoding**
boolean_categorical_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),
])

# **Pipeline for Log Transformation**
rightskew_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Pipeline for Humidity Features**
humidity_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler(with_centering=False))
])

# **Pipeline for Numerical Imputation & Scaling**
normal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Ordinal Encoding for Seasons**
season_ordinal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('ordinal_encode', OrdinalEncoder(categories=[['Summer', 'Autumn', 'Winter', 'Spring']])),
])

# **Pipeline for Polynomial Features (Degree 2)**
poly_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='mean')),
    ('poly', PolynomialFeatures(degree=5, include_bias=False)),  # Keeping degree moderate to prevent high dimensionality
    ('scale', StandardScaler()),
])

# **Final Column Transformer**
poly_preprocessor  = ColumnTransformer(transformers=[
    #('date_features', date_feature_pipe, ['Date']),
    ('cat_binary_pipe', cat_binary_pipe, ['Location', 'WindGustDir','WindDir9am', 'WindDir3pm']),
    ('boolean_categorical_pipe', boolean_categorical_pipe, ['RainToday', 'HeavyRainToday', 'StrongWindGust']),
    ('rightskew_pipe', rightskew_pipe, ["Rainfall", 'WindGustSpeed', 'PrevDayRainfall']),
    ('humidity_pipe', humidity_pipe, ["Humidity9am"]),
    ('normal_pipe', normal_pipe, ['Sunshine', 'Humidity3pm', 'Cloud9am', 'Cloud3pm']),
    ('season_ordinal_pipe', season_ordinal_pipe, ['Season']),
    ('poly_pipe', poly_pipe, ["Rainfall", "WindGustSpeed", "Humidity9am", "Humidity3pm"]),  # Added polynomial features
], remainder='passthrough')

# Transform data
#X_train_scaled = preprocessor.fit_transform(X_train)
#X_test_scaled = preprocessor.transform(X_test)

from imblearn.pipeline import Pipeline as Imb_Pipeline

oversampling_polyfeats_pipeline = Imb_Pipeline(steps=[
    ('poly_preprocessor', poly_preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
])

oversampling_polyfeats_pipeline

!pip install category_encoders==2.8.0

import numpy as np
import pandas as pd
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OrdinalEncoder, RobustScaler, FunctionTransformer, OneHotEncoder, PolynomialFeatures, StandardScaler
from sklearn.impute import SimpleImputer
from category_encoders.binary import BinaryEncoder

# Safe log transformation function
log_transformer = FunctionTransformer(
    lambda x: np.log1p(np.clip(np.nan_to_num(x, nan=0), a_min=1e-6, a_max=None)),
    validate=False
)



# **Pipeline for Binary Encoding**
cat_binary_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', BinaryEncoder(drop_invariant=False)),
])

# **Pipeline for One-Hot Encoding**
boolean_categorical_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('encode', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),
])

# **Pipeline for Log Transformation**
rightskew_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Pipeline for Humidity Features**
humidity_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    ('handle_outliers', log_transformer),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler(with_centering=False))
])

# **Pipeline for Numerical Imputation & Scaling**
normal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='median')),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),
    ('scale', RobustScaler())
])

# **Ordinal Encoding for Seasons**
season_ordinal_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='most_frequent')),
    ('ordinal_encode', OrdinalEncoder(categories=[['Summer', 'Autumn', 'Winter', 'Spring']])),
])

# **Pipeline for Polynomial Features (Degree 2)**
poly_pipe = Pipeline(steps=[
    ('handle_nans', SimpleImputer(strategy='mean')),
    #('poly', PolynomialFeatures(degree=5, include_bias=False)),  # Keeping degree moderate to prevent high dimensionality
    ('scale', StandardScaler()),
])

# **Final Column Transformer**
poly_preprocessor  = ColumnTransformer(transformers=[
    #('date_features', date_feature_pipe, ['Date']),
    ('cat_binary_pipe', cat_binary_pipe, ['Location', 'WindGustDir','WindDir9am', 'WindDir3pm']),
    ('boolean_categorical_pipe', boolean_categorical_pipe, ['RainToday', 'HeavyRainToday', 'StrongWindGust']),
    ('rightskew_pipe', rightskew_pipe, ["Rainfall", 'WindGustSpeed', 'PrevDayRainfall']),
    ('humidity_pipe', humidity_pipe, ["Humidity9am"]),
    ('normal_pipe', normal_pipe, ['Sunshine', 'Humidity3pm', 'Cloud9am', 'Cloud3pm']),
    ('season_ordinal_pipe', season_ordinal_pipe, ['Season']),
    #('poly_pipe', poly_pipe, ["Rainfall", "WindGustSpeed", "Humidity9am", "Humidity3pm"]),  # Added polynomial features
], remainder='passthrough')

# Transform data
#X_train_scaled = preprocessor.fit_transform(X_train)
#X_test_scaled = preprocessor.transform(X_test)

from imblearn.pipeline import Pipeline as Imb_Pipeline

oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(k_neighbors=1, random_state=42)),
])

oversampling_pipeline

X_train_df, y_train_df = oversampling_pipeline.fit_resample(X_train, y_train)
X_train_df = pd.DataFrame(X_train_df)
y_train_df = pd.DataFrame(y_train_df)
X_train_df.duplicated().sum()

y_train_df.value_counts()



"""********************

## (2) Underfitting vs Overfitting
We now know dataset in not linear
(so let's try [KNN - GaussianNB - SVC - DT - Ensamble])
"""

# Logestic Regression
from sklearn.model_selection import KFold
valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

oversampling_pipeline = Imb_Pipeline(steps=[
    ('poly_preprocessor', poly_preprocessor),
    ('solve_imbalanced', SMOTE(k_neighbors=5, random_state=42)),
    ("model", LogisticRegression(C=1.0, max_iter=500, random_state=42))
    ])
oversampling_pipeline.fit(X_train, y_train)
y_train_pred = oversampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(k_neighbors=5, random_state=42)),
    ("model", LogisticRegression(C=1.0, max_iter=500, random_state=42))
    ])

    oversampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = oversampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# KNN



from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", KNeighborsClassifier(n_neighbors=21, leaf_size=30))
    ])
oversampling_pipeline.fit(X_train, y_train)
y_train_pred = oversampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", KNeighborsClassifier(n_neighbors=21, leaf_size=30))
    ])

    oversampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = oversampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# GaussianNB



from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", GaussianNB())
    ])
oversampling_pipeline.fit(X_train, y_train)
y_train_pred = oversampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", GaussianNB())
    ])

    oversampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = oversampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# # SVC



# from sklearn.model_selection import KFold

# valid_accuracy_score = []
# valid_f1_score = []
# valid_precision_score = []
# valid_recall_score = []

# oversampling_pipeline = Imb_Pipeline(steps=[
#     ('preprocessor', preprocessor),
#     ('solve_imbalanced', SMOTE(random_state=42)),
#     ("model", SVC(C=1.0, kernel='poly', degree=4, coef0=10, random_state=42))
#     ])
# oversampling_pipeline.fit(X_train, y_train)
# y_train_pred = oversampling_pipeline.predict(X_train)
# print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

# skfolds = StratifiedKFold(n_splits=5)
# i = 1
# for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
#     print(f"At fold {i}")
#     # print(y_train.iloc[train_indx].value_counts(normalize=True))
#     # print(y_train.iloc[valid_indx].value_counts(normalize=True))
#     # print()

#     oversampling_pipeline = Imb_Pipeline(steps=[
#     ('preprocessor', preprocessor),
#     ('solve_imbalanced', SMOTE(random_state=42)),
#     ("model", SVC(C=1.0, kernel='poly', degree=4, coef0=10, random_state=42))
#     ])

#     oversampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
#     y_valid_pred = oversampling_pipeline.predict(X_train.iloc[valid_indx])

#     valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

#     i += 1

# print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
# print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
# print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
# print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# DT

from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', RandomUnderSampler(random_state=42)),
    ("model", DecisionTreeClassifier(max_depth=8, random_state=42, min_samples_split=9, min_samples_leaf=7))
    ])
oversampling_pipeline.fit(X_train, y_train)
y_train_pred = oversampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", DecisionTreeClassifier(max_depth=8, random_state=42, min_samples_split=9, min_samples_leaf=7))
    ])

    oversampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = oversampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# Logestic Regression

from sklearn.model_selection import KFold
params_grid = {'model__penalty': ['l2'],
               'model__C':[0.1, 1, 3, 5, 50],
               'poly_preprocessor__creditscore_estimated_pipe__poly__degree': [3, 5, 10],
               'poly_preprocessor__age_pipe__poly__degree': [3, 5, 10],
               'poly_preprocessor__balance_pipe__poly__degree': [3, 5, 10],
               }



oversampling_pipeline = Imb_Pipeline(steps=[
    ('poly_preprocessor', poly_preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", LogisticRegression(C=1.0, max_iter=1000, random_state=42)) # 135 Model
    ])

logestic_grid = HalvingGridSearchCV(oversampling_pipeline, params_grid, cv=3, n_jobs=-1, scoring='f1', random_state=42) # 405 Model

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 2025 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    logestic_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx]) # 405 Model
    best_logestic_model = logestic_grid.best_estimator_
    y_valid_pred = logestic_grid.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1



print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

best_logestic_model # only trained on 80%(80% train)

logestic_grid.best_params_

best_logestic_model.fit(X_train, y_train)

# KNN

from sklearn.model_selection import KFold
params_grid = {'model__n_neighbors': [5, 7, 9, 11, 15, 21, 31, 51, 71, 101],
               'model__leaf_size':[30, 40, 50, 60, 80, 100],
               }



oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", KNeighborsClassifier(n_neighbors=77, leaf_size=50)) # 135 Model
    ])

knn_grid = GridSearchCV(oversampling_pipeline, params_grid, cv=3, n_jobs=-1, scoring='f1') # 405 Model

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 2025 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    knn_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx]) # 405 Model
    best_knn_model = knn_grid.best_estimator_
    y_valid_pred = knn_grid.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1



print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

from sklearn.model_selection import StratifiedKFold, HalvingGridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from imblearn.pipeline import Pipeline as Imb_Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import numpy as np

# Optimized parameter grid
params_grid = {
    'model__n_neighbors': [5, 11, 21, 51, 101],  # Reduced unnecessary values
    'model__leaf_size': [30, 50, 80]  # Focus on essential leaf sizes
}

# Define pipeline
oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ('model', KNeighborsClassifier())  # No need to set hyperparameters initially
])

# Use Halving Grid Search for efficient parameter search
knn_grid = HalvingGridSearchCV(
    oversampling_pipeline,
    params_grid,
    cv=3,
    n_jobs=-1,
    scoring='f1',
    factor=3,  # Aggressive reduction in candidate estimators
    random_state=42,
    verbose=1
)

# Cross-validation performance tracking
valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Perform cross-validation
for i, (train_indx, valid_indx) in enumerate(skfolds.split(X_train, y_train), 1):
    print(f"At fold {i}")

    # Fit HalvingGridSearchCV
    knn_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])

    # Best KNN model from search
    best_knn_model = knn_grid.best_estimator_
    y_valid_pred = best_knn_model.predict(X_train.iloc[valid_indx])

    # Append validation metrics
    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

# Print validation results
print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score):.4f}")
print(f"Average Valid F1 Score: {np.mean(valid_f1_score):.4f}")
print(f"Average Valid Precision: {np.mean(valid_precision_score):.4f}")
print(f"Average Valid Recall: {np.mean(valid_recall_score):.4f}")

# Print best hyperparameters
print("Best Hyperparameters:", knn_grid.best_params_)

best_knn_model

knn_grid.best_params_

best_knn_model.fit(X_train, y_train)

# # SVC

# from sklearn.model_selection import KFold
# params_grid = [{'model__C': [0.1, 0.5, 1, 20, 50],
#                'model__kernel':['poly'],
#                'model__degree':[2, 3, 4],
#                'model__coef0':[5, 10],
#                },
#                {'model__C': [0.1, 0.5, 1, 20, 50],
#                'model__kernel':['rbf'],
#                'model__gamma':['scale', 0.1, 0.5, 0.8, 1],
#                }
#               ]



# oversampling_pipeline = Imb_Pipeline(steps=[
#     ('preprocessor', preprocessor),
#     ('solve_imbalanced', SMOTE(random_state=42)),
#     ("model", SVC(C=1.0, kernel='poly', degree=4, coef0=10, random_state=42)) # 55 Model
#     ])

# svm_clf_grid = HalvingGridSearchCV(oversampling_pipeline, params_grid, cv=3, n_jobs=-1, scoring='f1', random_state=42) # 165 Model

# valid_accuracy_score = []
# valid_f1_score = []
# valid_precision_score = []
# valid_recall_score = []

# skfolds = StratifiedKFold(n_splits=5)
# i = 1
# for train_indx, valid_indx in skfolds.split(X_train, y_train): # 825 Model
#     print(f"At fold {i}")

#     svm_clf_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
#     best_svm_clf_model = svm_clf_grid.best_estimator_
#     y_valid_pred = svm_clf_grid.predict(X_train.iloc[valid_indx])

#     valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

#     i += 1

# print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
# print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
# print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
# print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

from sklearn.model_selection import StratifiedKFold, HalvingGridSearchCV
from sklearn.svm import SVC
from imblearn.pipeline import Pipeline as Imb_Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import numpy as np

# Optimized parameter grid
params_grid = [
    {'model__C': [0.1, 1, 10],
     'model__kernel': ['poly'],
     'model__degree': [2, 3],
     'model__coef0': [5, 10]},

    {'model__C': [0.1, 1, 10],
     'model__kernel': ['rbf'],
     'model__gamma': ['scale', 0.1]}
]

# Define pipeline
oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", SVC(random_state=42))
])

# Perform Halving Grid Search (outside loop)
svm_clf_grid = HalvingGridSearchCV(
    oversampling_pipeline, params_grid, cv=2, n_jobs=-1, scoring='f1',
    factor=3, random_state=42, verbose=1
)

# Fit once before cross-validation
svm_clf_grid.fit(X_train, y_train)
best_svm_clf_model = svm_clf_grid.best_estimator_

# Cross-validation performance
valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for i, (train_indx, valid_indx) in enumerate(skfolds.split(X_train, y_train), 1):
    print(f"At fold {i}")

    # Train best model found in GridSearch
    best_svm_clf_model.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = best_svm_clf_model.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

# Print validation results
print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}")
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}")
print(f"Average Valid Precision: {np.mean(valid_precision_score)}")
print(f"Average Valid Recall: {np.mean(valid_recall_score)}")

# Print best hyperparameters
print("Best Hyperparameters:", svm_clf_grid.best_params_)

best_svm_clf_model

svm_clf_grid.best_params_

best_svm_clf_model.fit(X_train, y_train)

# DT

from sklearn.model_selection import KFold
params_grid = {'model__max_depth': [5, 10, 20],
               'model__max_leaf_nodes':[5, 10, 20],
               'model__min_samples_split':[20, 25, 30],
               'model__min_samples_leaf':[10, 20, 30],
               }

oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", DecisionTreeClassifier(max_depth=5, max_leaf_nodes=5, random_state=42, min_samples_split=20, min_samples_leaf=10)) # 135 Model
    ])

dt_clf_grid = GridSearchCV(oversampling_pipeline, params_grid, cv=3, n_jobs=-1, scoring='f1') # 405 Model

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 2025 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    dt_clf_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx]) # 405 Model
    best_dt_clf_model = dt_clf_grid.best_estimator_
    y_valid_pred = dt_clf_grid.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1
print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

best_dt_clf_model

dt_clf_grid.best_params_

best_dt_clf_model.fit(X_train, y_train)

"""## So Oversampling Models won (KNN - DT - ##SVM)
let's try now Ensemble Best Models
"""



"""************************************************

## 4) Ensemble Methods:
* 1) Bagging (RF, ExtraTrees)
* 2) Boosting (AdaBoost, GradientBoostingClassfier)
* 3) Voting
* 4) Stacking (Strongest One)
"""

# * 1) Bagging (RF, ExtraTrees)
from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestClassifier, ExtraTreesClassifier

# * 1) Bagging (RF, ExtraTrees)
from sklearn.ensemble import BaggingClassifier, BaggingRegressor, RandomForestClassifier, ExtraTreesClassifier
# RF Performance on Validation Set

from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", RandomForestClassifier(n_estimators=2500, max_samples=None, max_features='sqrt',max_depth=100, max_leaf_nodes=100, min_samples_leaf=3,
                       min_samples_split=3, n_jobs=-1, random_state=42)) # 135 Model
    ])
oversampling_pipeline.fit(X_train, y_train)
y_train_pred = oversampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")

    oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", RandomForestClassifier(n_estimators=2500, max_samples=None, max_features='sqrt',max_depth=100, max_leaf_nodes=100, min_samples_leaf=3,
                       min_samples_split=3, n_jobs=-1, random_state=42)) # 135 Model
    ])

    oversampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = oversampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# EXtraTrees Performance on Validation Set

from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", ExtraTreesClassifier(n_estimators=2500, max_samples=300, bootstrap=True, max_features='sqrt',max_depth=100, max_leaf_nodes=100, min_samples_leaf=3,
                       min_samples_split=3, n_jobs=-1, random_state=42)) # 135 Model
    ])
oversampling_pipeline.fit(X_train, y_train)
y_train_pred = oversampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")

    oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", ExtraTreesClassifier(n_estimators=2500, max_samples=300, bootstrap=True, max_features='sqrt',max_depth=100, max_leaf_nodes=100, min_samples_leaf=3,
                       min_samples_split=3, n_jobs=-1, random_state=42)) # 135 Model
    ])

    oversampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = oversampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall



# * 2) Boosting (AdaBoost, GradientBoostingClassfier)
from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier

# AdaBoost Performance on Validation Set

from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", AdaBoostClassifier(n_estimators=1000, learning_rate=1.0, random_state=42)) # DescionStumb
    ])
oversampling_pipeline.fit(X_train, y_train)
y_train_pred = oversampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")

    oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", AdaBoostClassifier(n_estimators=1000, learning_rate=1.0, random_state=42)) # 135 Model
    ])

    oversampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = oversampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

# AdaBoost Performance on Validation Set

from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", GradientBoostingClassifier(learning_rate=0.1, n_estimators=5000, n_iter_no_change=10, random_state=42)) # DescionStumb
    ])
oversampling_pipeline.fit(X_train, y_train)
y_train_pred = oversampling_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")

    oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", GradientBoostingClassifier(learning_rate=0.1, n_estimators=5000, n_iter_no_change=10, random_state=42)) # 135 Model
    ])

    oversampling_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = oversampling_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall



!pip install imblearn==0.0

!pip install imblearn==0.0

# RF

from sklearn.model_selection import KFold
params_grid = {'model__n_estimators': [1000, 2000, 2500, 3000],
               'model__max_depth':[80, 100, 120],
               'model__max_leaf_nodes':[80, 100, 120],
               'model__min_samples_split':[3, 5, 10],
               'model__min_samples_leaf':[3, 5, 10],
               }



oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", RandomForestClassifier(n_estimators=2500, max_samples=None, max_features='sqrt',max_depth=100, max_leaf_nodes=100, min_samples_leaf=3,
                       min_samples_split=3, n_jobs=-1, random_state=42))
    ])

rf_clf_grid = RandomizedSearchCV(oversampling_pipeline, params_grid, cv=3, n_jobs=-1, scoring='f1', random_state=42)

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 2025 Model
    print(f"At fold {i}")
    # print(y_train.iloc[train_indx].value_counts(normalize=True))
    # print(y_train.iloc[valid_indx].value_counts(normalize=True))
    # print()

    rf_clf_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx]) # 405 Model
    best_rf_clf_model = rf_clf_grid.best_estimator_
    y_valid_pred = rf_clf_grid.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

best_rf_clf_model

rf_clf_grid.best_params_

best_rf_clf_model.fit(X_train, y_train)

# best et model
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from imblearn.pipeline import Pipeline as Imb_Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.ensemble import ExtraTreesClassifier

# Define hyperparameter grid for ExtraTrees
params_grid = {
    'model__n_estimators': [1000, 2000, 2500, 3000],
    'model__max_depth': [80, 100, 120],
    'model__max_leaf_nodes': [80, 100, 120],
    'model__min_samples_split': [3, 5, 10],
    'model__min_samples_leaf': [3, 5, 10]
}

# Initialize pipeline with ExtraTrees Classifier
oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", ExtraTreesClassifier(n_estimators=2500, max_samples=300, bootstrap=True,
                                   max_features='sqrt', max_depth=100, max_leaf_nodes=100,
                                   min_samples_leaf=3, min_samples_split=3,
                                   n_jobs=-1, random_state=42))
])

# Initialize RandomizedSearchCV for tuning
et_clf_grid = RandomizedSearchCV(oversampling_pipeline, params_grid, cv=3, n_jobs=-1,
                                 scoring='f1', random_state=42)

# Store validation scores
valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

# Perform 5-Fold Cross-Validation
skfolds = StratifiedKFold(n_splits=5)
i = 1

for train_indx, valid_indx in skfolds.split(X_train, y_train):
    print(f"At fold {i}")

    # Fit model on training fold
    et_clf_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    best_et_clf_model = et_clf_grid.best_estimator_

    # Predict on validation fold
    y_valid_pred = best_et_clf_model.predict(X_train.iloc[valid_indx])

    # Store scores
    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

# Print average performance scores
print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score):.4f}")
print(f"Average Valid F1 Score: {np.mean(valid_f1_score):.4f}")
print(f"Average Valid Precision: {np.mean(valid_precision_score):.4f}")
print(f"Average Valid Recall: {np.mean(valid_recall_score):.4f}")

best_et_clf_model.fit(X_train, y_train)

from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import StratifiedKFold, cross_val_predict
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from imblearn.pipeline import Pipeline as Imb_Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import GridSearchCV
import numpy as np

# Reduced hyperparameter space for faster tuning
params_grid = {
    'model__n_estimators': [800, 1200, 2000]  # Reduced from 5 values to 3
}

# Define pipeline
oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", AdaBoostClassifier(learning_rate=1.0, random_state=42))  # Base model
])

# Use Stratified KFold
skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Optimize GridSearchCV (reducing computation)
adaboost_clf_grid = GridSearchCV(
    oversampling_pipeline,
    param_grid=params_grid,
    cv=2,  # Reduced from 3 to 2 for speed
    n_jobs=-1,  # Use all CPU cores
    scoring='recall',  # Prioritizing recall
    verbose=1
)

# Fit the model once to select best parameters
adaboost_clf_grid.fit(X_train, y_train)

# Best model from GridSearch
best_adaboost_clf_model = adaboost_clf_grid.best_estimator_

# Get cross-validation predictions
y_valid_pred = cross_val_predict(best_adaboost_clf_model, X_train, y_train, cv=skfolds, method='predict')

# Compute scores
valid_accuracy_score = accuracy_score(y_train, y_valid_pred)
valid_f1_score = f1_score(y_train, y_valid_pred)
valid_precision_score = precision_score(y_train, y_valid_pred)
valid_recall_score = recall_score(y_train, y_valid_pred)

# Print results
print(f"Valid Accuracy: {valid_accuracy_score:.4f}")
print(f"Valid F1 Score: {valid_f1_score:.4f}")
print(f"Valid Precision: {valid_precision_score:.4f}")
print(f"Valid Recall: {valid_recall_score:.4f}")  # Key metric for rain prediction

# # AdaBoost

# from sklearn.model_selection import KFold
# params_grid = {'model__n_estimators': [800, 1000, 1200, 2000, 3000],
#                }



# oversampling_pipeline = Imb_Pipeline(steps=[
#     ('preprocessor', preprocessor),
#     ('solve_imbalanced', SMOTE(random_state=42)),
#     ("model", AdaBoostClassifier(n_estimators=1000, learning_rate=1.0, random_state=42)) # 135 Model
#     ])

# adaboost_clf_grid = GridSearchCV(oversampling_pipeline, params_grid, cv=3, n_jobs=-1, scoring='f1') # 405 Model

# valid_accuracy_score = []
# valid_f1_score = []
# valid_precision_score = []
# valid_recall_score = []

# skfolds = StratifiedKFold(n_splits=5)
# i = 1
# for train_indx, valid_indx in skfolds.split(X_train, y_train): # 2025 Model
#     print(f"At fold {i}")
#     # print(y_train.iloc[train_indx].value_counts(normalize=True))
#     # print(y_train.iloc[valid_indx].value_counts(normalize=True))
#     # print()

#     adaboost_clf_grid.fit(X_train.iloc[train_indx], y_train.iloc[train_indx]) # 405 Model
#     best_adaboost_clf_model = adaboost_clf_grid.best_estimator_
#     y_valid_pred = adaboost_clf_grid.predict(X_train.iloc[valid_indx])

#     valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
#     valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

#     i += 1



# print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
# print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
# print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
# print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

best_adaboost_clf_model

adaboost_clf_grid.best_params_

best_adaboost_clf_model.fit(X_train, y_train)

from sklearn.model_selection import StratifiedKFold, HalvingGridSearchCV
from imblearn.pipeline import Pipeline as Imb_Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
import numpy as np
import xgboost as xgb

# Optimized parameter grid for XGBoost
params_grid = {
    'model__n_estimators': [50, 100, 200],  # Number of boosting rounds
    'model__learning_rate': [0.01, 0.1, 0.2],  # Step size shrinkage
    'model__max_depth': [3, 5, 7],  # Tree depth
    'model__subsample': [0.7, 1.0],  # Fraction of samples used per boosting round
    'model__colsample_bytree': [0.7, 1.0]  # Fraction of features used per tree
}

# Define pipeline with XGBoost
oversampling_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", xgb.XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False))
])

# Perform Halving Grid Search (outside loop)
xgb_clf_grid = HalvingGridSearchCV(
    oversampling_pipeline, params_grid, cv=2, n_jobs=-1, scoring='f1',
    factor=3, random_state=42, verbose=1
)

# Fit once before cross-validation
xgb_clf_grid.fit(X_train, y_train)
best_xgb_model = xgb_clf_grid.best_estimator_

# Cross-validation performance
valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

for i, (train_indx, valid_indx) in enumerate(skfolds.split(X_train, y_train), 1):
    print(f"At fold {i}")

    # Train best model found in GridSearch
    best_xgb_model.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = best_xgb_model.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

# Print validation results
print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score):.4f}")
print(f"Average Valid F1 Score: {np.mean(valid_f1_score):.4f}")
print(f"Average Valid Precision: {np.mean(valid_precision_score):.4f}")
print(f"Average Valid Recall: {np.mean(valid_recall_score):.4f}")

# Print best hyperparameters
print("Best Hyperparameters:", xgb_clf_grid.best_params_)

best_xgb_model.fit(X_train, y_train)# best_xgb_model

"""*******************************************
*********************************************

## Stacking Best 3 Models (knn -dt, xgbost)
"""

# # Using Voting
# from sklearn.ensemble import VotingClassifier, VotingRegressor # Ensemble (Voting)

# voting_clf = VotingClassifier(
#     estimators=[
#         ('KNN', RandomForestClassifier(n_estimators=300, max_depth=50, min_samples_leaf=5, min_samples_split=3, n_jobs=-1, random_state=42)),
#         #('ET', ExtraTreesClassifier(n_estimators=500, max_depth=50, min_samples_leaf=5, max_samples=0.8, bootstrap=True, n_jobs=-1, random_state=42)),
#         ('DT', DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5, random_state=42)),
#         ("xgb", xgb.XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False))
#     ],
#     voting='soft',
#     n_jobs=-1
# )

# voting_pipeline = Imb_Pipeline(steps=[
#     ('preprocessor', preprocessor),
#     ('solve_imbalanced', SMOTE(random_state=42)),
#     ("model", voting_clf) # 135 Model
#     ])
# voting_pipeline

# from sklearn.ensemble import VotingClassifier
# from sklearn.pipeline import Pipeline
# from imblearn.pipeline import Pipeline as Imb_Pipeline
# from imblearn.over_sampling import SMOTE
# from sklearn.preprocessing import StandardScaler
# from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier
# from sklearn.tree import DecisionTreeClassifier
# from sklearn.neighbors import KNeighborsClassifier
# import xgboost as xgb

# # Define individual models
# rf_clf = RandomForestClassifier(n_estimators=300, max_depth=50, min_samples_leaf=5, min_samples_split=3, n_jobs=-1, random_state=42)
# et_clf = ExtraTreesClassifier(n_estimators=500, max_depth=50, min_samples_leaf=5, max_samples=0.8, bootstrap=True, n_jobs=-1, random_state=42)
# dt_clf = DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5, random_state=42)
# xgb_clf = xgb.XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False)
# knn_clf = KNeighborsClassifier(n_neighbors=50)  # Fixed incorrect `KNN` variable name

# # Define the voting classifier
# voting_clf = VotingClassifier(
#     estimators=[
#         ('RandomForest', rf_clf),
#         ('ExtraTrees', et_clf),
#         ('DecisionTree', dt_clf),
#         ('XGBoost', xgb_clf),
#         ('KNN', knn_clf)  # Added KNN to the ensemble
#     ],
#     voting='soft',  # 'soft' voting averages probabilities; 'hard' voting takes majority vote
#     n_jobs=-1
# )

# # Define the pipeline
# voting_pipeline = Imb_Pipeline(steps=[
#     ('preprocessor', StandardScaler()),  # Standardize features for better model performance
#     ('solve_imbalanced', SMOTE(random_state=42)),  # Handle imbalanced data
#     ('model', voting_clf)  # Use Voting Classifier
# ])
# voting_pipeline

!pip install xgboost
import xgboost as xgb # Import the xgboost library and assign it the alias 'xgb'

#Voting

# Ensure preprocessor is defined before using
# Example: preprocessor = SomePreprocessingPipeline()

# Define base models
knn_clf = KNeighborsClassifier(n_neighbors=5)  # Adjust n_neighbors based on tuning
dt_clf = DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5, random_state=42)
xgb_clf = xgb.XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False) # Now you can use xgb.XGBClassifier

# Define the voting classifier
voting_clf = VotingClassifier(
    estimators=[
        ('KNN', knn_clf),
        ('DT', dt_clf),
        ('XGB', xgb_clf)
    ],
    voting='soft',
    n_jobs=-1
)

# Define the pipeline
voting_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),  # Apply preprocessing (scaling, encoding, etc.)
    ('solve_imbalanced', SMOTE(random_state=42)),  # Handle imbalanced data
    ('model', voting_clf)  # Use Voting Classifier
])
voting_pipeline

import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE

# Initialize lists to store validation scores
valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

# Define the VotingClassifier Pipeline once (avoid re-instantiating in the loop)
voting_pipeline = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", voting_clf)
])

# Fit on full training data before cross-validation
print("Training Voting Pipeline on Full Training Data...")
voting_pipeline.fit(X_train, y_train)
y_train_pred = voting_pipeline.predict(X_train)

print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred):.4f}")

# Stratified K-Fold Cross Validation
skfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Cross-validation loop
for i, (train_indx, valid_indx) in enumerate(skfolds.split(X_train, y_train), start=1):
    print(f"At fold {i}...")

    # Train model only on the training fold
    voting_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = voting_pipeline.predict(X_train.iloc[valid_indx])

    # Store performance metrics
    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

# Display average validation scores
print(f"Average Validation Accuracy: {np.mean(valid_accuracy_score):.4f}")
print(f"Average Validation F1 Score: {np.mean(valid_f1_score):.4f}")
print(f"Average Validation Precision: {np.mean(valid_precision_score):.4f}")
print(f"Average Validation Recall: {np.mean(valid_recall_score):.4f}")

voting_pipeline.fit(X_train, y_train)

"""## Stacking Classifier

"""

# Using Stacking
# Import required libraries
from sklearn.ensemble import StackingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.neighbors import KNeighborsClassifier
import xgboost as xgb
from imblearn.pipeline import Pipeline as Imb_Pipeline
from imblearn.over_sampling import SMOTE

# Define base models
knn_clf = KNeighborsClassifier(n_neighbors=50)
dt_clf = DecisionTreeClassifier(max_depth=5, min_samples_split=10, min_samples_leaf=5, random_state=42)
xgb_clf = xgb.XGBClassifier(objective='binary:logistic', random_state=42, use_label_encoder=False)

# Define Stacking Classifier with KNN as final estimator
stacking_clf = StackingClassifier(
    estimators=[
        ('DT', dt_clf),
        ('XGB', xgb_clf)
    ],
    final_estimator=KNeighborsClassifier(n_neighbors=5),  # KNN as meta-model
    cv=3,
    n_jobs=-1
)

# Define the pipeline
stacking_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ('model', stacking_clf)  # Stacking Model
])
stacking_pipeline

# StackingClassifier Performance on Validation Set

from sklearn.model_selection import KFold

valid_accuracy_score = []
valid_f1_score = []
valid_precision_score = []
valid_recall_score = []

stacking_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", stacking_clf) # 135 Model
])

stacking_pipeline.fit(X_train, y_train)
y_train_pred = stacking_pipeline.predict(X_train)
print(f"Train Accuracy: {accuracy_score(y_train, y_train_pred)}")

skfolds = StratifiedKFold(n_splits=5)
i = 1
for train_indx, valid_indx in skfolds.split(X_train, y_train): # 5 Model
    print(f"At fold {i}")

    stacking_pipeline = Imb_Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('solve_imbalanced', SMOTE(random_state=42)),
    ("model", stacking_clf) # 135 Model
    ])

    stacking_pipeline.fit(X_train.iloc[train_indx], y_train.iloc[train_indx])
    y_valid_pred = stacking_pipeline.predict(X_train.iloc[valid_indx])

    valid_accuracy_score.append(accuracy_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_f1_score.append(f1_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_precision_score.append(precision_score(y_train.iloc[valid_indx], y_valid_pred))
    valid_recall_score.append(recall_score(y_train.iloc[valid_indx], y_valid_pred))

    i += 1

print(f"Average Valid Accuracy: {np.mean(valid_accuracy_score)}") # Valid accuracy
print(f"Average Valid F1 Score: {np.mean(valid_f1_score)}") # Valid F1
print(f"Average Valid Precsion: {np.mean(valid_precision_score)}") # Valid Precsion
print(f"Average Valid Recall: {np.mean(valid_recall_score)}") # Valid Recall

stacking_pipeline.fit(X_train, y_train)

"""## (5) PR Curve on Validation **Data**

to determine threshold
"""

## P&R Curve.
print("Getting Voting Scores")
y_valid_voting_prob = cross_val_predict(voting_pipeline, X_train, y_train, cv=3, method='predict_proba')
print("Getting Stacking Scores")
y_valid_stacking_prob = cross_val_predict(stacking_pipeline, X_train, y_train, cv=3, method='predict_proba')
precision_voting_scores, recall_voting_scores, voting_thresholds = precision_recall_curve(y_train, y_valid_voting_prob[:, 1])
precision_stacking_scores, recall_stacking_scores, stacking_thresholds = precision_recall_curve(y_train, y_valid_stacking_prob[:, 1])
##
plt.plot(precision_voting_scores[:-1], recall_voting_scores[:-1], label='voting', color='blue')
plt.plot(precision_stacking_scores[:-1], recall_stacking_scores[:-1], label='stacking', color='red')
plt.legend()
plt.xlabel('recall')
plt.ylabel('precision')
# so we can pick threshold at precision = , Recall=

y_valid_voting_predict = cross_val_predict(voting_pipeline, X_train, y_train, cv=3, method='predict')
confusion_matrix(y_train, y_valid_voting_predict)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Generate confusion matrix
cm = confusion_matrix(y_train, y_valid_voting_predict)

# Plot the confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix for Voting Classifier")
plt.show()

y_valid_stacking_predict = cross_val_predict(stacking_pipeline, X_train, y_train, cv=3, method='predict')
confusion_matrix(y_train, y_valid_stacking_predict)

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix

# Generate confusion matrix
cm = confusion_matrix(y_train, y_valid_stacking_predict)

# Plot the confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0', 'Class 1'], yticklabels=['Class 0', 'Class 1'])
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix for Stacking Classifier")
plt.show()

import matplotlib.pyplot as plt
from sklearn.model_selection import cross_val_predict
from sklearn.metrics import precision_recall_curve
from sklearn.compose import ColumnTransformer  # Import ColumnTransformer

# Assuming poly_preprocessor is your ColumnTransformer object
X_train_transformed = poly_preprocessor.fit_transform(X_train)
X_test_transformed = poly_preprocessor.transform(X_test)

# Cross-validation predictions for base models using transformed data
y_valid_dt_prob = cross_val_predict(dt_clf, X_train_transformed, y_train, cv=3, method='predict_proba')
y_valid_xgb_prob = cross_val_predict(xgb_clf, X_train_transformed, y_train, cv=3, method='predict_proba')
y_valid_knn_prob = cross_val_predict(knn_clf, X_train_transformed, y_train, cv=3, method='predict_proba')  # Added KNN

# Compute Precision-Recall curves for DT, XGB, and KNN
precision_dt, recall_dt, _ = precision_recall_curve(y_train, y_valid_dt_prob[:, 1])
precision_xgb, recall_xgb, _ = precision_recall_curve(y_train, y_valid_xgb_prob[:, 1])
precision_knn, recall_knn, _ = precision_recall_curve(y_train, y_valid_knn_prob[:, 1])

# Plot Precision-Recall curves for the best models
plt.figure(figsize=(8, 6))
plt.plot(recall_dt, precision_dt, label='Decision Tree (DT)', color='red')
plt.plot(recall_xgb, precision_xgb, label='XGBoost (XGB)', color='green')
plt.plot(recall_knn, precision_knn, label='K-Nearest Neighbors (KNN)', color='blue')

# Formatting the plot
plt.legend()
plt.grid()
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve for Best Models')

# Show the plot
plt.show()

plt.plot(precision_voting_scores[:-1], recall_voting_scores[:-1], label='voting', color='black')
plt.plot(precision_stacking_scores[:-1], recall_stacking_scores[:-1], label='stacking', color='orange')
plt.plot(recall_dt, precision_dt, label='Decision Tree (DT)', color='red')
plt.plot(recall_xgb, precision_xgb, label='XGBoost (XGB)', color='green')
plt.plot(recall_knn, precision_knn, label='K-Nearest Neighbors (KNN)', color='blue')
plt.legend()
plt.grid()
plt.xlabel('recall')
plt.ylabel('precision') # best one at Recall=80% and Precision will be near 50% (good)

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve

# Compute ROC Curve for Voting and Stacking
fpr_voting, tpr_voting, _ = roc_curve(y_train, y_valid_voting_prob[:, 1])
fpr_stacking, tpr_stacking, _ = roc_curve(y_train, y_valid_stacking_prob[:, 1])

# Compute ROC Curve for DT, XGB, and KNN
fpr_dt, tpr_dt, _ = roc_curve(y_train, y_valid_dt_prob[:, 1])
fpr_xgb, tpr_xgb, _ = roc_curve(y_train, y_valid_xgb_prob[:, 1])
fpr_knn, tpr_knn, _ = roc_curve(y_train, y_valid_knn_prob[:, 1])

# Compute Precision-Recall Curve for DT, XGB, and KNN
precision_dt, recall_dt, _ = precision_recall_curve(y_train, y_valid_dt_prob[:, 1])
precision_xgb, recall_xgb, _ = precision_recall_curve(y_train, y_valid_xgb_prob[:, 1])
precision_knn, recall_knn, _ = precision_recall_curve(y_train, y_valid_knn_prob[:, 1])

# Plot ROC Curves
plt.figure(figsize=(10, 6))
plt.plot(fpr_voting, tpr_voting, label=f'Voting AUC = {roc_auc_score(y_train, y_valid_voting_prob[:, 1]):.2f}', color='orange')
plt.plot(fpr_stacking, tpr_stacking, label=f'Stacking AUC = {roc_auc_score(y_train, y_valid_stacking_prob[:, 1]):.2f}', color='black')

plt.plot(fpr_dt, tpr_dt, label=f'Decision Tree (DT) AUC = {roc_auc_score(y_train, y_valid_dt_prob[:, 1]):.2f}', color='red')
plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost (XGB) AUC = {roc_auc_score(y_train, y_valid_xgb_prob[:, 1]):.2f}', color='green')
plt.plot(fpr_knn, tpr_knn, label=f'K-Nearest Neighbors (KNN) AUC = {roc_auc_score(y_train, y_valid_knn_prob[:, 1]):.2f}', color='blue')

# Formatting the plot
plt.legend()
plt.grid()
plt.xlabel('False Positive Rate (FPR)')
plt.ylabel('True Positive Rate (TPR)')
plt.title('ROC Curve for Best Models')

# Show the plot
plt.show()

# # Plot Precision-Recall Curves
# plt.figure(figsize=(10, 6))
# plt.plot(recall_dt, precision_dt, label='Decision Tree (DT)', color='red')
# plt.plot(recall_xgb, precision_xgb, label='XGBoost (XGB)', color='green')
# plt.plot(recall_knn, precision_knn, label='K-Nearest Neighbors (KNN)', color='blue')

# # Formatting the plot
# plt.legend()
# plt.grid()
# plt.xlabel('Recall')
# plt.ylabel('Precision')
# plt.title('Precision-Recall Curve for Best Models')

# # Show the plot
# plt.show()

# import xgboost as xgb
# from sklearn.pipeline import Pipeline

# # Define the XGBoost model
# xgb_clf = xgb.XGBClassifier(random_state=42)

# # Create the XGBoost pipeline
# xgb_pipeline = Pipeline(steps=[
#     ('preprocessor', poly_preprocessor),  # Replace poly_preprocessor with your actual preprocessor
#     ('classifier', xgb_clf),
# ])

# # Now you can use xgb_pipeline in cross_val_predict
# y_xgb_prob = cross_val_predict(xgb_pipeline, X_train, y_train, cv=3, method='predict_proba')

# Find the threshold where recall is closest to 0.80
indx = np.argmax(recall_voting_scores >= 0.80)  # Ensure recall is at least 0.80
t_80_recall = voting_thresholds[indx]

# Cross-validation predictions for Voting Classifier
y_voting_prob = cross_val_predict(voting_pipeline, X_train, y_train, cv=3, method='predict_proba')

# Apply threshold based on recall
y_voting_threshold_pred = (y_voting_prob[:, 1] >= t_80_recall)

# Print performance metrics (focus on Recall)
print(f"Recall: {recall_score(y_train, y_voting_threshold_pred):.4f} ✅ (Key Metric)")
print(f"Precision: {precision_score(y_train, y_voting_threshold_pred):.4f}")
print(f"F1 Score: {f1_score(y_train, y_voting_threshold_pred):.4f}")
print(f"Accuracy: {accuracy_score(y_train, y_voting_threshold_pred):.4f}")
print(f"Selected Threshold: {t_80_recall:.4f}")

confusion_matrix(y_train, y_voting_threshold_pred)

"""## (6) Test Performance and CI

"""

import xgboost as xgb
from sklearn.pipeline import Pipeline

# ... (Your existing code for defining the pipeline)

# Fit the pipeline on the entire training data
voting_pipeline.fit(X_train, y_train)

# Now you can use xgb_pipeline to predict on the test set
y_voting_test_pred = voting_pipeline.predict(X_test)
print(f"Test Accuracy: {accuracy_score(y_test, y_voting_test_pred)}")
print(f"Test F1 Score: {f1_score(y_test, y_voting_test_pred)}")
print(f"Test Precsion: {precision_score(y_test, y_voting_test_pred)}")
print(f"Test Recall: {recall_score(y_test, y_voting_test_pred)}")

confusion_matrix(y_test, y_voting_test_pred)

# Predict probabilities for the test set
y_voting_test_scores = voting_pipeline.predict_proba(X_test)

# Apply the threshold based on recall optimization
y_voting_test_threshold_pred = (y_voting_test_scores[:, 1] >= t_80_recall)

# Print performance metrics (focus on Recall)
print(f"Test Recall: {recall_score(y_test, y_voting_test_threshold_pred):.4f}  (Key Metric)")
print(f"Test Precision: {precision_score(y_test, y_voting_test_threshold_pred):.4f}")
print(f"Test F1 Score: {f1_score(y_test, y_voting_test_threshold_pred):.4f}")
print(f"Test Accuracy: {accuracy_score(y_test, y_voting_test_threshold_pred):.4f}")
print(f"Selected Threshold: {t_80_recall:.4f}")

confusion_matrix(y_test, y_voting_test_threshold_pred)

"""## (7) Save Model"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install dill  # Install the 'dill' module

import dill

# ... (Your existing code to define the pipeline) ...

# Open a file in write binary ('wb') mode:
with open('voting_pipeline.pkl', 'wb') as file:
    dill.dump(voting_pipeline, file)

# When loading, use dill.load:
# with open('voting_pipeline.pkl', 'rb') as file:
#     voting_pipeline = dill.load(file)

#joblib.dump(voting_pipeline, 'voting_pipeline.pkl')

